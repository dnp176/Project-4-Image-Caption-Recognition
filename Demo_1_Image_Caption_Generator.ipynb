{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GURxGCDDKYNB"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yW_pP0ZZ1Tfw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "from keras.preprocessing import image, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbJIXY_JK5sc"
   },
   "outputs": [],
   "source": [
    "# data=\"/content/drive/MyDrive/Image Caption Generator/Images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCNTNhvzMnWR"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpSr-LogMsMf"
   },
   "outputs": [],
   "source": [
    "# with ZipFile(data,\"r\") as zip1:\n",
    "#  zip1.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuAD_-MQM4YP"
   },
   "outputs": [],
   "source": [
    "images_dir = os.listdir(\"D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4LSKsLTNK7H"
   },
   "outputs": [],
   "source": [
    "images_path = 'D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Images'\n",
    "captions_path = 'D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Flickr_TextData\\Flickr8k.token.txt'\n",
    "train_path = 'D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Flickr_TextData\\Flickr_8k.trainImages.txt'\n",
    "val_path = 'D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Flickr_TextData\\Flickr_8k.devImages.txt'\n",
    "test_path = 'D:\\PROGRAMMING\\PYTHON\\Data Science & Analysis\\Pr_4_Image Caption Generator\\flickr8k-sau\\Flickr_Data\\Flickr_TextData\\Flickr_8k.testImages.txt'\n",
    "\n",
    "captions = open(captions_path, 'r').read().split(\"\\n\")\n",
    "x_train = open(train_path, 'r').read().split(\"\\n\")\n",
    "x_val = open(val_path, 'r').read().split(\"\\n\")\n",
    "x_test = open(test_path, 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyOW-n0BNjqU"
   },
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcpNwMMONrHz"
   },
   "outputs": [],
   "source": [
    "print(len(captions))\n",
    "captions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcDr4kCWNwEz"
   },
   "outputs": [],
   "source": [
    "tokens = {}  #empty dictionary\n",
    "\n",
    "for ix in range(len(captions)-1):\n",
    "    temp = captions[ix].split(\"#\")\n",
    "    if temp[0] in tokens:\n",
    "        tokens[temp[0]].append(temp[1][2:])\n",
    "    else:\n",
    "        tokens[temp[0]] = [temp[1][2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mqbhw9sTN08k"
   },
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8ui0ghqN4EL"
   },
   "outputs": [],
   "source": [
    "temp = captions[201].split(\"#\")\n",
    "from IPython.display import Image, display\n",
    "z = Image(filename=images_path+\"/\"+temp[0])\n",
    "display(z)\n",
    "\n",
    "for ix in range(len(tokens[temp[0]])):\n",
    "    print(tokens[temp[0]][ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdqdWYFkOBMk"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "temp = captions[467].split(\"#\")\n",
    "z = Image(filename=images_path+\"/\"+temp[0])\n",
    "display(z)\n",
    "\n",
    "for ix in range(len(tokens[temp[0]])):\n",
    "    print(tokens[temp[0]][ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z21BpJziONhY"
   },
   "outputs": [],
   "source": [
    "x_imgs=[]\n",
    "captions=[]\n",
    "for img in x_train:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        caption = \" \"+ capt + \" \"\n",
    "        x_imgs.append(img)\n",
    "        captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijOiP37zOQL3"
   },
   "outputs": [],
   "source": [
    "data={'images':x_imgs,'captions':captions}\n",
    "df=pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74xVaW1rOVZ2"
   },
   "outputs": [],
   "source": [
    "words = [i.split() for i in captions]\n",
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)\n",
    "unique = list(set(unique))\n",
    "print(len(unique))\n",
    "vocab_size = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJ09ZWjKOZb3"
   },
   "outputs": [],
   "source": [
    "word_2_indices = {val:index for index, val in enumerate(unique)}\n",
    "indices_2_word = {index:val for index, val in enumerate(unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Pk3c2cxOdZ9"
   },
   "outputs": [],
   "source": [
    "word_2_indices['GF'] = 0\n",
    "indices_2_word[0] = 'GF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsajpQzeOf5s"
   },
   "outputs": [],
   "source": [
    "with open( \"w2i.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(word_2_indices, pickle_f )\n",
    "with open( \"i2w.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(indices_2_word, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCS9djD2Oife"
   },
   "outputs": [],
   "source": [
    "with open('/content/w2i.p', 'rb') as f:\n",
    "    word_2_indices= pickle.load(f, encoding=\"bytes\")\n",
    "with open('/content/i2w.p', 'rb') as f:\n",
    "    indices_2_word= pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoE78tJUOlx8"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word_2_indices.keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yLCI1OqOoW8"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in captions:\n",
    "    i = i.split()\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6TSDOeMOp5O"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_sequences, subsequent_words = [], []\n",
    "for ix in tqdm(range(len(captions))):\n",
    "    partial_seqs = []\n",
    "    next_words = []\n",
    "    text = captions[ix].split()\n",
    "    text = [word_2_indices[i] for i in text]\n",
    "    for i in range(1, len(text)):\n",
    "        partial_seqs.append(text[:i])\n",
    "        next_words.append(text[i])\n",
    "    padded_partial_seqs = pad_sequences(partial_seqs, maxlen=max_len, padding='post')\n",
    "    next_words_1hot = np.zeros([len(next_words), vocab_size], dtype=np.bool)\n",
    "    \n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_words_1hot[i, next_word] = 1\n",
    "        \n",
    "    padded_sequences.append(padded_partial_seqs)\n",
    "    subsequent_words.append(next_words_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7W2PD8uPQSC"
   },
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3YpPKSiPWYf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "def preprocessing(img_path):\n",
    "    im = load_img(img_path, target_size=(224,224,3))\n",
    "    im = img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aD3TAJ9PZnC"
   },
   "outputs": [],
   "source": [
    "imgs={}\n",
    "for i in tqdm(x_train[:6000]):\n",
    "    if i in imgs.keys():\n",
    "        continue\n",
    "    path = images_path + \"/\"+ i\n",
    "    img = preprocessing(path)\n",
    "    pred = model.predict(img).reshape(2048)\n",
    "    imgs[i]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YnvMavZZX2q"
   },
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZH-faZYZcDC"
   },
   "outputs": [],
   "source": [
    "with open( \"proces_imgs.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(imgs, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkpawC2-Zilq"
   },
   "outputs": [],
   "source": [
    "with open('/content/proces_imgs.p', 'rb') as f:\n",
    "    imgs= pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IubgHHxqZ3s2"
   },
   "outputs": [],
   "source": [
    "img = []\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    if df.iloc[i, 0] in imgs.keys():\n",
    "        img.append(imgs[df.iloc[i, 0]])\n",
    "\n",
    "img = np.asarray(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUcPDOp9Z8PY"
   },
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQk8yWVqaA4Y"
   },
   "outputs": [],
   "source": [
    "language_model = Sequential()\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT-ofGpab9DU"
   },
   "outputs": [],
   "source": [
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avTp3yaBb89A"
   },
   "outputs": [],
   "source": [
    "def tr_gen(inp,ne_words,batch_size=256):\n",
    "    cap=inp[1]\n",
    "    imgs=inp[0]\n",
    "    while True:\n",
    "        for i in range(0,30000-batch_size,batch_size):\n",
    "            n_words=[]\n",
    "            i_cap=[]\n",
    "            im=[]\n",
    "            for j in range(batch_size):\n",
    "                n_words.extend(ne_words[i+j].tolist())\n",
    "                i_cap.extend(cap[i+j].tolist())\n",
    "            for ix in range(i,i+batch_size):\n",
    "                for iy in range(cap[ix].shape[0]):\n",
    "                    im.append(imgs[ix])\n",
    "                \n",
    "            i_cap=np.array(i_cap)\n",
    "            n_words=np.asarray(n_words)\n",
    "            im= np.asarray(im)\n",
    "        \n",
    "            yield [im,i_cap],n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRtT3kkgcFZ3"
   },
   "outputs": [],
   "source": [
    "train_gen=tr_gen([img,padded_sequences],subsequent_words,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "421xro7qcIY0"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('best_model_acc.h5', monitor = 'accuracy' , mode = 'max', verbose = 1 , save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIL357Qrdhuj"
   },
   "outputs": [],
   "source": [
    "hist=model.fit_generator(train_gen,steps_per_epoch=30000//3000,callbacks = [mc],epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUeEhzv7cQ2d"
   },
   "outputs": [],
   "source": [
    "def preprocessing(img_path):\n",
    "    im = image.load_img(img_path, target_size=(224,224,3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwTZ7fyocSpT"
   },
   "outputs": [],
   "source": [
    "def get_encoding(model, img):\n",
    "    image = preprocessing(img)\n",
    "    pred = model.predict(image).reshape(2048)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sy8PGjZecUtu"
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODTmQyKYcWmc"
   },
   "outputs": [],
   "source": [
    "l=os.listdir('/content/Images')\n",
    "l[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJVL8VTycbz7"
   },
   "outputs": [],
   "source": [
    "img = '/content/Images/'+l[4680]\n",
    "# img='../input/backgrd-sample-imgs/2019-02-10-13-40-01-855.jpg'\n",
    "test_img = get_encoding(resnet, img)\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "\n",
    "def preprocessing(img):\n",
    "    im = Image.open(img)\n",
    "    im = im.resize((224, 224))  # Resize the image to the desired size\n",
    "    im = kimage.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZW5h1qZceMr"
   },
   "outputs": [],
   "source": [
    "def predict_captions(image):\n",
    "    start_word = [\"\"]\n",
    "    while True:\n",
    "        try:\n",
    "            par_caps = [word_2_indices[i] for i in start_word]\n",
    "        except KeyError:\n",
    "            break\n",
    "        \n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_len, padding='post')\n",
    "        preds = model.predict([np.array([image]), np.array(par_caps)])\n",
    "        word_pred = indices_2_word[np.argmax(preds[0])]\n",
    "        start_word.append(word_pred)\n",
    "        \n",
    "        if word_pred == \"\" or len(start_word) > max_len:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(start_word[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgS4cuY6v7vz"
   },
   "outputs": [],
   "source": [
    "# Argmax_Search = predict_captions(test_img)\n",
    "# z = Image(filename=img)\n",
    "# display(z)\n",
    "\n",
    "print(predict_captions(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
